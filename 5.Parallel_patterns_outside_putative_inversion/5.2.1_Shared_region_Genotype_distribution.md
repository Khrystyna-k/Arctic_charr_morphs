
## Step 1: Predicting genotypes based on genotype likelihoods using angsd
```{r}

#!/bin/bash -l

#SBATCH -A naiss2024-5-277
#SBATCH -p core
#SBATCH -n 4
#SBATCH -t 00-07:00:00
#SBATCH --array=1
#SBATCH -J GL_shar
#SBATCH -e GL_shar_%A_%a.err
#SBATCH -o GL_shar_%A_%a.out
#SBATCH --mail-type=all
#SBATCH --mail-user=khrystyna.kurta@imbim.uu.se

#Load modules
module load bioinfo-tools
module load samtools/1.12
module load bamtools/2.5.1
module load ANGSD/0.933


#Index sites 
SITES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/GL_MAF_GENO_SHARED/sites_homo_shared_filter

#angsd sites index $SITES

#Path to the directory where you have the bam-files
BASEDIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/Run_1_2
cd $BASEDIR

#STEP 1: Define paths to Refference genome
REFGENOME=/proj/snic2020-2-19/private/arctic_charr/assemblies/fSalAlp1.1/Data_Package_fSalAlp1_assembly_20231024/fSalAlp1.1.hap1.cur.20231016.fasta
REF_INDEXED=/proj/snic2020-2-19/private/arctic_charr/assemblies/fSalAlp1.1/Data_Package_fSalAlp1_assembly_20231024/fSalAlp1.1.hap1.cur.20231016.fasta.fai

CHUNK_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST


##STEP 2: Determine chromosome/ or Get all the contig (or scaffold) names from the reference genome fasta file
CHUNK_NAMES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST

#CHUNK_NAMES_target=$(ls $CHUNK_NAMES/shared_34chr*.region)
#CHUNK_NAMES_target_name=${CHUNK_NAMES_target/.region/}

#STEP 3: Create bam file list
#Text file containing sample bam paths
BAM_LIST=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/BAM_LISTS/SHARED_list/Shared_34chr

BAM=$(ls $BAM_LIST/Myv_Thin_all_homo.list | sed -n ${SLURM_ARRAY_TASK_ID}p)
BAM_LIST_NAME=$(basename $BAM)

#ls /proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/Run_1_2/*.bam > all_bam_path.list
#BAM_LIST=all_bam_path.list

OUT_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/GL_MAF_GENO_SHARED


#STEP 5: Run ANGSD

for CHUNK in `ls $CHUNK_NAMES/shared_34chr_outside.region`; do

CHUNK_NAMES_target_name=$(basename $CHUNK)
CHUNK_NAMES_target_name=${CHUNK_NAMES_target_name/.region/}

echo "Run angsd for $CHUNK and bam list $BAM"

angsd -b $BAM \
-ref $REFGENOME -fai $REF_INDEXED \
-rf $CHUNK \
-uniqueOnly 1 -remove_bads 1 -only_proper_pairs 1 -minMapQ 30 -minQ 20 \
-gl 2 -trim 0 -doMajorMinor 4 -domaf 1 -doPost 2 -doGlf 2 -minMaf 0.05 -SNP_pval 1e-6 -docounts 1 -dogeno 2 \
-out $OUT_DIR/${BAM_LIST_NAME}_${CHUNK_NAMES_target_name}_Maf0.05 -P 10 \
-nThreads 10
# -sites $SITES
done
```

## Step 2: Plot genotype distribution heatmap
```{r}
dir <- "~/Desktop/Comp_UU/REF_SalAlp_UK/Shared_regions"

#Load sample names 
bams <- read.csv("~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/all_bam_pca_lakes.list")


#Load data 
files <- list.files(dir)


# Select files of interest
desired_files <- grep("geno.gz$", files, value = TRUE)

# Read the desired files
geno_list <- list()

for(file in desired_files) {
  file_content <- read.table(file.path(dir, file), header = F)
  
  #Add colnames
  colnames(file_content)[3:287] <- bams$SampleID
  colnames(file_content)[1] <- 'Chromosome'
  colnames(file_content)[2] <- 'Position'
  
  file_content$SNP_ID <- paste(file_content$Chromosome, file_content$Position, sep = "_")
  
  # Save
  geno_list[[file]] <- file_content
  
}


#Remove two Myv-12 and MyvK-20 as missclassified species
remove_list <- c("Myv-12", "MyvK-20")
geno_all <- geno_list[[file]][, !colnames(geno_list[[file]]) %in% remove_list ]


#Load GWAS file for Benthic vs Pelagic groups
dir_gwas <- '~/Desktop/Comp_UU/REF_SalAlp_UK/GWAS/Data'

gwas_Thi_DB_LB_vs_PL_Pi <- read.table(file.path(dir_gwas, 'Thi_DB_LB_vs_PL_Pi.pvalue'), header = T)

#Add filter parameters
bonf = 1e-8/nrow(gwas_Thi_DB_LB_vs_PL_Pi) #alpha = 10ˆ-8


#Filter
gwas_Thi_DB_LB_vs_PL_Pi_bonf <- gwas_Thi_DB_LB_vs_PL_Pi[gwas_Thi_DB_LB_vs_PL_Pi$pvalue < bonf,]

#Filter based on chr of interest
gwas_Thi_DB_LB_vs_PL_Pi_bonf_reg <- gwas_Thi_DB_LB_vs_PL_Pi_bonf[ gwas_Thi_DB_LB_vs_PL_Pi_bonf$Chromosome == 34, ]


#Add SNP Id column
gwas_Thi_DB_LB_vs_PL_Pi_bonf_reg$SNP_ID <- paste(gwas_Thi_DB_LB_vs_PL_Pi_bonf_reg$Chromosome, gwas_Thi_DB_LB_vs_PL_Pi_bonf_reg$Position, sep = "_")


chr_data = gwas_Thi_DB_LB_vs_PL_Pi_bonf_reg
chr_data = chr_data[chr_data$Position >= 18340000 &
                    chr_data$Position <= 18450000,]

#Make a longer matrix
geno_sign_position <- geno_all[geno_all$SNP_ID %in% chr_data$SNP_ID, ]


# Convert to longer format:
geno_sign_position %>%
  pivot_longer(cols=3:285,names_to="individuals",values_to="genotypes") -> table_geno_sign_position  # Make sure your number of columns is correct!! I have 91 individuals, so I want to pivot columns 3 to 93, since first two columns are the CHROM and POS.

table_geno_sign_position$Position <- as.character(table_geno_sign_position$Position)


#MAKE A MATRIX Each row - one individual
library(tidyverse)
geno_sign_position_heatmap <- 
  pivot_wider(table_geno_sign_position[, -c(1,3)],
              names_from = Position,
              values_from = genotypes)


#Add sample information 
geno_sign_position_heat_id <- 
  geno_sign_position_heatmap %>% 
  left_join(bams, by = c('individuals' = 'SampleID'))
geno_sign_position_heat_id <- geno_sign_position_heat_id[!geno_sign_position_heat_id$individuals %in% remove_list, ]

#Order data based on levels 
level.order = c('ThiSB', 'ThiLB', 'ThiP', 'ThiPL',"MyvSB", 'MyvLG', 'SirD', 'SirN', 'VanD', 'VanN')

#
geno_sign_position_heat_id_order <- geno_sign_position_heat_id[order(match(geno_sign_position_heat_id$Morph_lake, level.order)),]


#Choose reference samples (in our case it is all benthic morphs)
geno_sign_position_heat_Benthic_Thin <- 
  geno_sign_position_heat_id[geno_sign_position_heat_id$Morph_lake == 'ThiSB'|
                             geno_sign_position_heat_id$Morph_lake == 'ThiLB', ]

#Replace NA in each column 
geno_sign_position_heat_Benthic_Thin[geno_sign_position_heat_Benthic_Thin == -1] <- NA



#Select reference allele as the most comman allele in benthic morphs


#Add row sum row at the end - a reference column
geno_sign_position_heat_Benthic_Thin <- 
  geno_sign_position_heat_Benthic_Thin %>%
  bind_rows(summarise_all(., ~if(is.numeric(.)) sum(.,na.rm = T) else "RefSumGeno"))

#Add number of NAs in each column
geno_sign_position_heat_Benthic_Thin_sumNA <- 
  geno_sign_position_heat_Benthic_Thin %>%
  bind_rows(summarise_all(., ~if(is.numeric(.)) sum(is.na(.)) else "RefSumNA"))


#select only two row sums
RefSumGeno <- geno_sign_position_heat_Benthic_Thin_sumNA[(nrow(geno_sign_position_heat_Benthic_Thin_sumNA)-1):nrow(geno_sign_position_heat_Benthic_Thin_sumNA),] 

#invert the matrix
RefSumGeno <- data.frame(t(RefSumGeno))          


#how many nonNA colums = nInd -  number of NAs
RefSumGeno$RefSumNoNA <- (nrow(geno_sign_position_heat_Benthic_Thin_sumNA)-2) - as.numeric(RefSumGeno$X2) 


#Account for NA values 
RefSumGeno$RefSumGeno_with_geno <- round(as.numeric(RefSumGeno$X1)/(RefSumGeno$RefSumNoNA*2),1)

#Select all above 0.5
RefSumGenoSNP_above05 <- RefSumGeno[RefSumGeno$RefSumGeno_with_geno >= 0.5, ]
RefSumGenoSNP_above05_list <- data.frame(rownames(na.omit(RefSumGenoSNP_above05)))
colnames(RefSumGenoSNP_above05_list) <- 'SNP_list'


#This is modified chunk

#Select data based on SNP list
geno_sign_position_heat_id_SelectRefSNP <- geno_sign_position_heat_id 

#Replace NA
geno_sign_position_heat_id_SelectRefSNP[geno_sign_position_heat_id_SelectRefSNP == -1] <- NA

# Check if column names are in the SNP list
cols_to_subtract <- colnames(geno_sign_position_heat_id_SelectRefSNP) %in% RefSumGenoSNP_above05_list$SNP_list

# Subtract genotypes from 2 where necessary
geno_sign_position_heat_id_SelectRefSNP[, cols_to_subtract] <- 2 - geno_sign_position_heat_id_SelectRefSNP[, cols_to_subtract]

geno_sign_position_heat_id_SelectRefSNP_AltGeno <- geno_sign_position_heat_id_SelectRefSNP

#Replace NA back to -1
geno_sign_position_heat_id_SelectRefSNP_AltGeno[is.na(geno_sign_position_heat_id_SelectRefSNP_AltGeno)] <- -1

#Prepare to plot Heat map
unique(geno_sign_position_heat_id_SelectRefSNP_AltGeno$Morph_lake)

#Order data based on levels 
level.order = c('ThiSB', 'ThiLB', 'ThiP', 'ThiPL',"MyvSB", 'MyvLG', 'SirD', 'SirN', 'VanD', 'VanN')

geno_sign_position_heat_id_SelectRefSNP_id_order <- geno_sign_position_heat_id_SelectRefSNP_AltGeno[order(match(geno_sign_position_heat_id_SelectRefSNP_AltGeno$Morph_lake, level.order)),]


#Prepare matrix
n_snps = dim(geno_sign_position_heat_id_SelectRefSNP_AltGeno)[2]-7
datamatrix <- 
  as.matrix(
    geno_sign_position_heat_id_SelectRefSNP_id_order[,2:n_snps])

#Add rownames                                             
row.names(datamatrix) <- unique(geno_sign_position_heat_id_order$individuals)

#Add row annotations
sampleInfo <- 
  geno_sign_position_heat_id_SelectRefSNP_id_order[,c((n_snps+1):ncol(geno_sign_position_heat_id_SelectRefSNP_id_order))]

sampleInfo <- data.frame(sampleInfo)
row.names(sampleInfo) <- row.names(datamatrix)

#Check the number of samples
#dim(datamatrix)
#dim(sampleInfo)

#Heatmap plot

library(ComplexHeatmap)

# Set up colors
color_list <- list(
   Morph =  c( 
    "DB" = "blue",
    "LP" = "gold",
    'LB' = 'darkslateblue',
    'SB' = 'deepskyblue3',
    'Pi' = 'coral3',
    'PL' = 'chartreuse3',
    "LG" = "darkred"))

# Create annotation for rows
annot <- 
  rowAnnotation( 
    Morph = sampleInfo$Morph_short,
    col = color_list,
    show_annotation_name = FALSE )

# Add row split
row_split <- factor(sampleInfo$Lake, levels = c("Thingvallavatn", "Mývatn", "Sirdalsvatnet", "Vangsvatnet"))

# Add column split

# Add chromosome name and the number of SNP
chr <- unique(chr_data$Chromosome)
n_snps <- dim(geno_sign_position_heat_id_SelectRefSNP_AltGeno)[2]-7

# Plot a heatmap using ComplexHeatmap
pdf(file.path(dir, paste('Heatmap_geno_allPop_chr34.pdf', sep = ".")), 
    width = 5.5, height = 5.5)
Heatmap(datamatrix, col = c('lightgrey', 'steelblue1',"yellow1",'brown') ,
        row_names_gp = gpar(fontsize = 7), cluster_rows = FALSE, cluster_columns = FALSE,
        cluster_row_slices = FALSE,
        row_order = rownames(datamatrix), 
        column_order = colnames(datamatrix),
        row_split =  row_split, 
       # column_split = col_split,
        border = T,
        column_title = paste('Scaffold 34: 18.36-18.45 Mb' ),
        show_column_names = FALSE, show_row_names = FALSE,
        show_row_dend = FALSE, show_column_dend = FALSE,
        row_title_rot = 90,
        left_annotation = annot,
        heatmap_legend_param = list(title = "Genotype", at = c(-1,0, 1, 2), 
                                    labels = c("NA", "0", "1", "2")))


dev.off()


```


## Step 3:Pairwise diff analysis - another approach to select individuals witht a specific genotype
### Pairwise diff analysis
```{r }
#Assign data
data <- geno_sign_position_heat_id
n_snp_ids <- ncol(geno_sign_position_heatmap)-1

#Subset genotypes only
genotype <- as.matrix(data[, 2:n_snp_ids]) 

rownames(genotype) <- data$individuals
genotype[genotype== -1] <- NA
genotype_Thin <- genotype[grep('Thi|Myv', rownames(genotype)), ]


```


###Estimate the pairwise differences between individual genotypes
```{r }

# Compute pairwise distances directly
pairwise_differences <- as.matrix(dist(genotype_Thin, method = "manhattan") / (2 * n_snp_ids))

#Check the ranges of the distances 
range(pairwise_differences, na.rm = T)
hist(pairwise_differences, breaks=60)


# Reshape pairwise distances into a vector
distance_vector <- as.vector(pairwise_differences[lower.tri(pairwise_differences, diag = FALSE)])
clusters <- kmeans(distance_vector, centers = 3)

# Extract cluster centers and sort
cluster_centers <- sort(clusters$centers)

# Assign thresholds based on sorted cluster centers
left_mean <- cluster_centers[1]  # Left distribution (homozygous for one allele)
middle_mean <- cluster_centers[2]  # Middle distribution (heterozygous)
right_mean <- cluster_centers[3]  # Right distribution (homozygous for another allele)

# Create a list to store individuals in each cluster
cluster_distances <- split(distance_matrix, distance_labels)

# Calculate standard deviations for each cluster
cluster_sd <- sapply(cluster_distances, sd)

# Adjust the left and right threshold 
rght = as.numeric(round(right_threshold-6*cluster_sd[3], 2))
lft = as.numeric(round(left_threshold+5*cluster_sd[1], 2))
rght
lft
```

###Chi square test 
```{r }
# Overlay expected trinomial distribution
chisq.test(table(pairwise_differences))

```

###Select individuals
```{r }
#Select individuals
ind_list_homP <-rownames(pairwise_differences)[which(pairwise_differences[1,] <= lft)]
ind_list_het <-rownames(pairwise_differences)[which(pairwise_differences[1,] < rght & pairwise_differences[1,] > lft) ]
ind_list_homB <-rownames(pairwise_differences)[which(pairwise_differences[1,] >= rght) ]

ind_list_homB
ind_list_homP
ind_list_het

#Check
length(ind_list_homB)
length(ind_list_homP)
length(ind_list_het)

sum(ind_list_homB %in% ind_list_homP)
sum(ind_list_homB %in% ind_list_het)
sum(ind_list_homP %in% ind_list_het)

```


```{r }
pairwise_diff_allSNP_homoz <- 
  pairwise_differences[c(ind_list_homB,ind_list_homP), c(ind_list_homB,ind_list_homP)]

pairwise_diff_allSNP_homB <- 
  pairwise_differences[c(ind_list_homB), c(ind_list_homB)]

pairwise_diff_allSNP_homP <- 
  pairwise_differences[ind_list_homP, ind_list_homP]

pairwise_diff_allSNP_homPvB <- 
  pairwise_differences[ind_list_homP, ind_list_homB]

pairwise_diff_allSNP_homBvP <- 
  pairwise_differences[ind_list_homB, ind_list_homP]

pairwise_diff_allSNP_het <-
pairwise_differences[ind_list_het,ind_list_het ]


hist(pairwise_diff_allSNP_homoz, breaks = 60)
hist(pairwise_diff_allSNP_homB, breaks = 60)
hist(pairwise_diff_allSNP_homP, breaks = 30)
hist(pairwise_diff_allSNP_homPvB, breaks = 60)
hist(pairwise_diff_allSNP_het, breaks = 60)


#Get a mean value per individuals------------------------------------
#Homoz benthic
pairwise_diff_allSNP_homB_add_lower <- pairwise_diff_allSNP_homB
pairwise_diff_allSNP_homB_add_lower[lower.tri(pairwise_diff_allSNP_homB_add_lower)]  <- 
 t( pairwise_diff_allSNP_homB_add_lower)[lower.tri(pairwise_diff_allSNP_homB_add_lower)]
pairwise_diff_allSNP_homB_individual_means <- rowMeans(pairwise_diff_allSNP_homB_add_lower, na.rm=T)

#Homoz Pelagic
pairwise_diff_allSNP_homP_add_lower <- pairwise_diff_allSNP_homP
pairwise_diff_allSNP_homP_add_lower[lower.tri(pairwise_diff_allSNP_homP_add_lower)]  <- 
  t( pairwise_diff_allSNP_homP_add_lower)[lower.tri(pairwise_diff_allSNP_homP_add_lower)]
pairwise_diff_allSNP_homP_individual_means <- rowMeans(pairwise_diff_allSNP_homP_add_lower, na.rm=T)

#Heterozygous
pairwise_diff_allSNP_het_add_lower <- pairwise_diff_allSNP_het
pairwise_diff_allSNP_het_add_lower[lower.tri(pairwise_diff_allSNP_het_add_lower)]  <- 
 t(pairwise_diff_allSNP_het_add_lower)[lower.tri(pairwise_diff_allSNP_het_add_lower)]

pairwise_diff_allSNP_het_individual_means <- rowMeans(pairwise_diff_allSNP_het_add_lower, na.rm=T)


#Create vectors
pairwise_diff_allSNP_homB_vec <- as.numeric(pairwise_diff_allSNP_homB_individual_means)

pairwise_diff_allSNP_homP_vec <- as.numeric(pairwise_diff_allSNP_homP_individual_means)

pairwise_diff_allSNP_het_vec <- as.numeric(pairwise_diff_allSNP_het_individual_means)

pairwise_diff_allSNP_het_vec <- pairwise_diff_allSNP_het_vec[!is.na(pairwise_diff_allSNP_het_vec)]


#Remove Nas
pairwise_diff_allSNP_homPvB_vec <- as.numeric(pairwise_diff_allSNP_homPvB)
pairwise_diff_allSNP_homPvB_vec <- pairwise_diff_allSNP_homPvB_vec[!is.na(pairwise_diff_allSNP_homPvB_vec)]
length(pairwise_diff_allSNP_homPvB_vec)

pairwise_diff_allSNP_homBvP_vec <- as.numeric(pairwise_diff_allSNP_homBvP)
pairwise_diff_allSNP_homBvP_vec <- pairwise_diff_allSNP_homBvP_vec[!is.na(pairwise_diff_allSNP_homBvP_vec)]
length(pairwise_diff_allSNP_homBvP_vec)

pairwise_diff_allSNP_homBvP_comined <- c(pairwise_diff_allSNP_homBvP_vec, pairwise_diff_allSNP_homPvB_vec)

#Run t.test to check for significance of selected distributions
t.test(x = pairwise_diff_allSNP_homB_vec, y = pairwise_diff_allSNP_homP_vec)
t.test(x = pairwise_diff_allSNP_homB_vec, y = pairwise_diff_allSNP_homBvP_comined)
t.test(x = pairwise_diff_allSNP_homP_vec, y = pairwise_diff_allSNP_homBvP_comined)


#Plot boxplots with stats comparisons between homB, homP, and with across group comparisons
homB_vec <- data.frame(pairwise_diff_allSNP_homB_vec)
homP_vec <- data.frame(pairwise_diff_allSNP_homP_vec)
het_vec <- data.frame(pairwise_diff_allSNP_het_vec)


homB_vec$Group <- 'Homozygous major (benthic)'
homP_vec$Group <- 'Homozygous minor (pelagic)'
het_vec$Group <- 'Heterozygous (across groups)'

colnames(homB_vec)[1] <- 'Distance'
colnames(homP_vec)[1] <- 'Distance'
colnames(het_vec)[1] <- 'Distance'

all_pairwised_dif_selectedInd <- rbind(homB_vec,homP_vec,het_vec)

sum_table <- all_pairwised_dif_selectedInd %>%
  group_by(Group) %>%
  summarise(n = n(),
            mean = mean(Distance),
            sd = sd(Distance))

```


## Step 4: Save list of haplotype groups
```{r}
#Read bam file list and add lake infor
bams <- read.csv("~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/all_bam_pca_lakes.list")

myv_thin_ind_homoB <- as.data.frame(ind_list_homB)
myv_thin_ind_homoP <- as.data.frame(ind_list_homP)
myv_thin_ind_het <- as.data.frame(ind_list_het)

#Summary
b <- myv_thin_ind_homoB %>% group_by(Morph_lake) %>% summarise(n = n())
p <- myv_thin_ind_homoP %>% group_by(Morph_lake) %>% summarise(n = n())
h <- myv_thin_ind_het %>% group_by(Morph_lake) %>% summarise(n = n())

#Add sample information
myv_thin_ind_homoB <- left_join(myv_thin_ind_homoB, bams, by = c("ind_list_homB" = "SampleID"))
myv_thin_ind_homoP <- left_join(myv_thin_ind_homoP, bams, by = c("ind_list_homP" = "SampleID"))
myv_thin_ind_het <- left_join(myv_thin_ind_het, bams, by = c("ind_list_het" = "SampleID"))

colnames(myv_thin_ind_homoB)[1] <- "homo"
colnames(myv_thin_ind_homoP)[1] <- "homo"
myv_thin_all <- rbind(myv_thin_ind_homoB, myv_thin_ind_homoP )

#Save bam list to generate GL, NJ tree.
#All
write.table(myv_thin_ind_homoB[,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Myv_Thin_homoB.list', row.names = F, col.names = F, quote = F)
write.table(myv_thin_ind_homoP[,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Myv_Thin_homoP.list', row.names = F, col.names = F, quote = F)
write.table(myv_thin_all[,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Myv_Thin_all_homo.list', row.names = F, col.names = F, quote = F)

#Myvatn
write.table(myv_thin_ind_homoP[myv_thin_ind_homoP$Lake == "Mývatn",][,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Myv_homoP.list', row.names = F, col.names = F, quote = F)
write.table(myv_thin_ind_homoB[myv_thin_ind_homoB$Lake == "Mývatn",][,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Myv_homoB.list', row.names = F, col.names = F, quote = F)

#Thingvalla
write.table(myv_thin_ind_homoB[myv_thin_ind_homoB$Lake == "Thingvallavatn",][,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Thin_homoB.list', row.names = F, col.names = F, quote = F)
write.table(myv_thin_ind_homoP[myv_thin_ind_homoP$Lake == "Thingvallavatn",][,2], '~/Desktop/Comp_UU/REF_SalAlp_UK/BAM_list/Shared_34chr/Thin_homoP.list', row.names = F, col.names = F, quote = F)

```
