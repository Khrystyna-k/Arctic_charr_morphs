## Step1: Compute Site Frequency Spectrum (SFS) and FST with ANGSD

```{r}
#!/bin/bash -l

#SBATCH -A uppmax2025-2-114
#SBATCH -p core -n 20
#SBATCH -t 02-00:00:00
#SBATCH --array=1-40
#SBATCH -J sfs
#SBATCH -e sfs_%A_%a.err
#SBATCH -o sfs_%A_%a.out
#SBATCH --mail-type=all
#SBATCH --mail-user=khrystyna.kurta@slu.se

#Load modules
module load bioinfo-tools
module load ANGSD/0.933
module load R_packages/4.3.1


#     PARAMETERS & PATHS     #


# Minimum depth per site per individual
MIN_DEPTH=1

# Max depth: Set to 3x average depth to exclude repetitive regions
MAX_DEPTH_FACTOR=3

# Number of threads to use
NB_CPU=10

# Path to R script used for processing 2DSFS output
rscript=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_MAF0.05_FOLDED/Rscripts/01_sum_sites_2dsfs.r

# Directory containing chromosome/scaffold region files
CHUNK_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST

# File with list of scaffold/chromosome regions
CHUNK_NAMES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST/chr_ordered_txt.list
CHUNK_NAMES_target=$(sed -n ${SLURM_ARRAY_TASK_ID}p $CHUNK_NAMES)
CHUNK_NAMES_target_name=${CHUNK_NAMES_target/.txt/}

# Directory containing BAM files
BASEDIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/Run_1_2

# List of BAM files grouped per population
BAM_LIST=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/BAM_LISTS/FST_list

# Reference genome and index
REFGENOME=/proj/snic2020-2-19/private/arctic_charr/assemblies/fSalAlp1.1/Data_Package_fSalAlp1_assembly_20231024/fSalAlp1.1.hap1.cur.20231016.fasta
REF_INDEXED=${REFGENOME}.fai

# Genomic sites to use
SITES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/SITES/sites_sorted.txt

# Number of sites to use in realSFS for 2D SFS estimation
NSITES=500000

# Output directory
OUT_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_MAF0.05_FOLDED/LAKES


#     STEP 1: SFS per POP    #


cd $BASEDIR

for POP in $BAM_LIST/pop_*list; do
    OUTPUT=$(basename $POP)
    N_IND=$(wc -l < $POP)

    # Set required percentage of individuals with data
    if [ "$N_IND" -lt 12 ]; then
        PERCENT_IND=0.9
    else
        PERCENT_IND=0.5
    fi

    # Compute the required number of individuals per site
    MIN_IND=$(printf "%.0f" $(echo "$N_IND * $PERCENT_IND" | bc))

    echo " Processing $OUTPUT ($N_IND individuals)"
    echo " - PERCENT_IND = $PERCENT_IND → MIN_IND = $MIN_IND"

    angsd -P $NB_CPU \
        -doSaf 1 -GL 2 -doMajorMinor 5 \
        -anc $REFGENOME -fai $REF_INDEXED \
        -minMapQ 30 -minQ 20 -remove_bads 1 \
        -setMinDepthInd $MIN_DEPTH -minInd $MIN_IND \
        -sites $SITES \
        -rf $CHUNK_DIR/$CHUNK_NAMES_target \
        -bam $POP \
        -out $OUT_DIR/${OUTPUT}_${CHUNK_NAMES_target_name}
done


#     STEP 2: FST Analysis   #


cd $OUT_DIR
POP_LIST=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_folded/pop.list
populations=($(cat $POP_LIST))

for ((i = 0; i < ${#populations[@]} - 1; i++)); do
  for ((j = i + 1; j < ${#populations[@]}; j++)); do
    pop_1="${populations[$i]}"
    pop_2="${populations[$j]}"
    
    echo " Comparing: $pop_1 vs $pop_2 on $CHUNK_NAMES_target_name"

    ## Step 2.1: Estimate 2D Site Frequency Spectrum
    realSFS ${pop_1}_${CHUNK_NAMES_target_name}.saf.idx \
            ${pop_2}_${CHUNK_NAMES_target_name}.saf.idx \
            -P $NB_CPU -maxIter 30 -nSites $NSITES > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}

    ## Step 2.2: Summarize 2D SFS in R
    Rscript $rscript "${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}"

    ## Step 2.3: FST index preparation
    realSFS fst index ${pop_1}_${CHUNK_NAMES_target_name}.saf.idx \
                      ${pop_2}_${CHUNK_NAMES_target_name}.saf.idx \
                      -sfs ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.2dsfs \
                      -P $NB_CPU \
                      -fstout ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}

    ## Step 2.4: Extract per-site FST estimates
    realSFS fst print ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                      -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.bypos.sfs

    ## Step 2.5: Global genome-wide FST estimate
    realSFS fst stats ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                      -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst

    ## Step 2.6: Sliding window FST
    realSFS fst stats2 ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                       -win 20000 -step 10000 -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}_20kb_10kbstep.slidingwindow

    realSFS fst stats2 ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                       -win 25000 -step 5000 -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}_25kb_5kbstep.slidingwindow
  done
done


```

### R script used to estimate 2sfs
```{r}
01_sum_sites_2dsfs.r
# code R to take the sfs made on a subsample of sites in a usable format for subsequent analyses
argv <- commandArgs(T)
file<-argv[1]


sfs<-read.table (paste0(file))

sfs.sum<-colSums(sfs)
write.table(rbind(sfs.sum),  quote=F, col.names=F, row.names=F,paste0(file, ".2dsfs"))
```


## Step 2: Calcultae Fst statistics per each lake
```{r}

#Libs
library(tidyverse)
library(patchwork)
library(zoo)
library(data.table)
library(dplyr)
library(scales)
library(ggplot2)
options(scipen = 999)
library(reshape2)


#Directory
dir <- '~/Desktop/Comp_UU/REF_SalAlp_UK/FST/FST_MAF005/FST_files'

#Load data 
files <- list.files(dir)


# Filter files 
desired_files <- grep("_20kb_10kbstep.slidingwindow$", files, value = TRUE)
col_names <- c('chr', 'midPos','Nsites', 'Fst')

# Read the desired files
fst_list <- list()

for(file in desired_files) {
  # Try to read the file content, handle any errors gracefully
  file_content <- try(read.table(file.path(dir, file), header = TRUE, sep = "\t", stringsAsFactors = FALSE), silent = TRUE)

  # Check if the read operation resulted in an error or if the file is empty
  if (inherits(file_content, "try-error") || nrow(file_content) == 0) {
    next  # Skip to the next file in the loop
  }
  
  #file_content <- read.table(file.path(dir, file), header = F)[,-1]
  colnames(file_content) <- col_names
  
  #Names of pops

  pops <- str_extract_all(file, "(?<=pop_)[A-Za-z]+(?=\\.list)")[[1]]
  #pops <- gsub("0", "", pops)
  
  file_content$Population <- paste(pops[1], pops[2], sep = "_")

  # Process the file content as needed
  fst_list[[file]] <- file_content
}

#Combine and filter for > 10 sites
fst_combined <- do.call(rbind, fst_list)
fst_combined_filter <- fst_combined[fst_combined$Nsites >= 10,]

#Check if all chromosomes are present
fst_stats <- fst_combined_filter %>%
                group_by(Population) %>%
                summarise(n_chr = n_distinct(chr),
                          n_sites = sum(Nsites),
                          mean_Fst = round(mean(Fst),2 ),
                          sd_fst = sd(Fst)
)


#Check if all chromosomes are present
fst_stats_lake <- fst_combined_filter %>%
                group_by(chr) %>%
                summarise(
                          n_sites = sum(Nsites),
                          mean_Fst = round(mean(Fst),2 ),
                          sd_fst = sd(Fst)
)

```


## Step 3: Plot Fst Pairwise for All lakes
```{r}
#Fst stats
fst_stats$Pop2 <- fst_stats$Population
fst_stats$Pop2 <- sub(".*_","", fst_stats$Pop2)
fst_stats$Population <- sub("^.*_(.*)_.*$", "\\1", fst_stats$Population)

# Create a named vector for the replacements
fst_stats$Population <- case_when(startsWith(fst_stats$Population, "Myv") ~ "Mývatn",
                                   startsWith(fst_stats$Population,"Van")~ "Vangsvatnet",
                                   startsWith(fst_stats$Population,"Thin")~ "Thingvallavatn",
                                   startsWith(fst_stats$Population,"Sir")~ "Sirdalsvatnet",
                                   )
fst_stats$Pop2 <- case_when(startsWith(fst_stats$Pop2, "Myv") ~ "Mývatn",
                                   startsWith(fst_stats$Pop2,"Van")~ "Vangsvatnet",
                                   startsWith(fst_stats$Pop2,"Thin")~ "Thingvallavatn",
                                   startsWith(fst_stats$Pop2,"Sir")~ "Sirdalsvatnet",
                                   )
# Add reverse combinations (symmetry) so that pop1 -> pop2 and pop2 -> pop1 are both represented

fst_data_dir <- data.frame(
  pop2 = fst_stats$Population,
  pop1 = fst_stats$Pop2,
  Fst = fst_stats$mean_Fst
)

fst_data_rev <- data.frame(
  pop1 = fst_stats$Population,
  pop2 = fst_stats$Pop2,
  Fst = fst_stats$mean_Fst
)

# Combine original and reverse data
fst_full <- rbind(fst_data_dir, fst_data_rev)

# Add diagonal values (Fst between the same population is 0)
unique_pops <- unique(c(fst_full$pop1, fst_full$pop2))
diag_data <- data.frame(
  pop1 = unique_pops,
  pop2 = unique_pops,
  Fst = 0
)

# Combine with diagonal data
fst_full <- rbind(fst_full, diag_data)

# Create a symmetric matrix
fst_matrix <- matrix(0, nrow = length(unique_pops), ncol = length(unique_pops),
                     dimnames = list(unique_pops, unique_pops))

# Fill the matrix with Fst values
for (i in 1:nrow(fst_full)) {
  fst_matrix[fst_full$pop1[i], fst_full$pop2[i]] <- fst_full$Fst[i]
}


#Order lakes 
desired_order <-  c("Mývatn", "Thingvallavatn", "Sirdalsvatnet", "Vangsvatnet")
fst_matrix_ordered <- fst_matrix[desired_order, desired_order, drop = FALSE]

#Prepare matrix to plot heatmap 
library(corrplot)
bright_colors <- colorRampPalette(c("blue", "orange"))(100)

pdf("~/Desktop/Comp_UU/REF_SalAlp_UK/PCA_NJ_tree/Fst_plot.pdf", width = 6, height = 5)
corrplot(fst_matrix_ordered, 
         method = 'number', 
         type = 'lower', 
         tl.col = "black",  
         tl.cex = 1.2,        # Adjust the size of the labels
         col = bright_colors, 
         diag = FALSE, 
         number.cex = 1.2,    # Increase the size of the numbers in the plot
         legend.cex = 1.5)    # Increase the size of the legend text
dev.off()

```

