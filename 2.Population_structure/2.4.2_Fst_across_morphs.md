## Step 1: Compute Site Frequency Spectrum (SFS) and FST with ANGSD
```{r}
#!/bin/bash -l

#SBATCH -A uppmax2025-2-114
#SBATCH -p core -n 20
#SBATCH -t 02-00:00:00
#SBATCH --array=1-40
#SBATCH -J fst
#SBATCH -e fst_%A_%a.err
#SBATCH -o fst_%A_%a.out
#SBATCH --mail-type=all
#SBATCH --mail-user=khrystyna.kurta@slu.se

#Load modules
module load bioinfo-tools
module load ANGSD/0.933
module load R_packages/4.3.1


#     PARAMETERS & PATHS     #


# Minimum depth per site per individual
MIN_DEPTH=1

# Max depth: Set to 3x average depth to exclude repetitive regions
MAX_DEPTH_FACTOR=3

# Number of threads to use
NB_CPU=10

# Path to R script used for processing 2DSFS output
rscript=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_MAF0.05_FOLDED/Rscripts/01_sum_sites_2dsfs.r

# Directory containing chromosome/scaffold region files
CHUNK_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST

# File with list of scaffold/chromosome regions
CHUNK_NAMES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/CHUNK_LIST/chr_ordered_txt.list
CHUNK_NAMES_target=$(sed -n ${SLURM_ARRAY_TASK_ID}p $CHUNK_NAMES)
CHUNK_NAMES_target_name=${CHUNK_NAMES_target/.txt/}

# Directory containing BAM files
BASEDIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/Run_1_2

# List of BAM files grouped per population
BAM_LIST=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/BAM_LISTS/FST_list

# Reference genome and index
REFGENOME=/proj/snic2020-2-19/private/arctic_charr/assemblies/fSalAlp1.1/Data_Package_fSalAlp1_assembly_20231024/fSalAlp1.1.hap1.cur.20231016.fasta
REF_INDEXED=${REFGENOME}.fai

# Genomic sites to use
SITES=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/SITES/sites_sorted.txt

# Number of sites to use in realSFS for 2D SFS estimation
NSITES=500000

# Output directory
OUT_DIR=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_MAF0.05_FOLDED/LAKES


#     STEP 1: SFS per POP    #


cd $BASEDIR

for POP in $BAM_LIST/maf_*list; do
    OUTPUT=$(basename $POP)
    N_IND=$(wc -l < $POP)

    # Set required percentage of individuals with data
    if [ "$N_IND" -lt 12 ]; then
        PERCENT_IND=0.9
    else
        PERCENT_IND=0.5
    fi

    # Compute the required number of individuals per site
    MIN_IND=$(printf "%.0f" $(echo "$N_IND * $PERCENT_IND" | bc))

    echo " Processing $OUTPUT ($N_IND individuals)"
    echo " - PERCENT_IND = $PERCENT_IND → MIN_IND = $MIN_IND"

    angsd -P $NB_CPU \
        -doSaf 1 -GL 2 -doMajorMinor 5 \
        -anc $REFGENOME -fai $REF_INDEXED \
        -minMapQ 30 -minQ 20 -remove_bads 1 \
        -setMinDepthInd $MIN_DEPTH -minInd $MIN_IND \
        -sites $SITES \
        -rf $CHUNK_DIR/$CHUNK_NAMES_target \
        -bam $POP \
        -out $OUT_DIR/${OUTPUT}_${CHUNK_NAMES_target_name}
done


#     STEP 2: FST Analysis   #


cd $OUT_DIR
POP_LIST=/proj/snic2020-2-19/private/herring/users/khrystyna/Arctic_charr_ref_fSalAlp1/FST_folded/pop.list
populations=($(cat $POP_LIST))

for ((i = 0; i < ${#populations[@]} - 1; i++)); do
  for ((j = i + 1; j < ${#populations[@]}; j++)); do
    pop_1="${populations[$i]}"
    pop_2="${populations[$j]}"
    
    echo " Comparing: $pop_1 vs $pop_2 on $CHUNK_NAMES_target_name"

    ## Step 2.1: Estimate 2D Site Frequency Spectrum
    realSFS ${pop_1}_${CHUNK_NAMES_target_name}.saf.idx \
            ${pop_2}_${CHUNK_NAMES_target_name}.saf.idx \
            -P $NB_CPU -maxIter 30 -nSites $NSITES > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}

    ## Step 2.2: Summarize 2D SFS in R
    Rscript $rscript "${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}"

    ## Step 2.3: FST index preparation
    realSFS fst index ${pop_1}_${CHUNK_NAMES_target_name}.saf.idx \
                      ${pop_2}_${CHUNK_NAMES_target_name}.saf.idx \
                      -sfs ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.2dsfs \
                      -P $NB_CPU \
                      -fstout ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}

    ## Step 2.4: Extract per-site FST estimates
    realSFS fst print ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                      -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.bypos.sfs

    ## Step 2.5: Global genome-wide FST estimate
    realSFS fst stats ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                      -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst

    ## Step 2.6: Sliding window FST
    realSFS fst stats2 ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                       -win 20000 -step 10000 -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}_20kb_10kbstep.slidingwindow

    realSFS fst stats2 ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}.fst.idx \
                       -win 25000 -step 5000 -P $NB_CPU > ${pop_1}.${pop_2}.${CHUNK_NAMES_target_name}.${NSITES}_25kb_5kbstep.slidingwindow
  done
done


```

### R script used to estimate 2sfs
```{r}
01_sum_sites_2dsfs.r
# code R to take the sfs made on a subsample of sites in a usable format for subsequent analyses
argv <- commandArgs(T)
file<-argv[1]


sfs<-read.table (paste0(file))

sfs.sum<-colSums(sfs)
write.table(rbind(sfs.sum),  quote=F, col.names=F, row.names=F,paste0(file, ".2dsfs"))
```


## Step 2: Calcultae Fst statistics per each morph pair within lakes
```{r}
#Libs
library(tidyverse)
library(patchwork)
library(zoo)
library(data.table)
library(dplyr)
library(scales)
library(ggplot2)
options(scipen = 999)


#Directory
dir <- '~/Desktop/Comp_UU/REF_SalAlp_UK/FST/FST_MAF005/FST_MORPHS'


#Load data 
files <- list.files(dir)

# Filter files that start with numbers from 1 to 13 and end with ""
desired_files <- grep("_20kb_10kbstep.slidingwindow$", files, value = TRUE)

# Define exclusion patterns
exclude_patterns <- c("list\\.2\\.", "list\\.6\\.", "list\\.7\\.", "list\\.10\\.", "list\\.11\\.")

# Exclude files matching the exclusion patterns
keep <- !grepl(paste(exclude_patterns, collapse = "|"), desired_files)
filtered_files <- desired_files[keep]

col_names <- c('chr', 'midPos','Nsites', 'Fst')

# Read the desired files
fst_list <- list()

for(file in filtered_files) {
  file_content <- read.table(file.path(dir, file), header = TRUE, sep = "\t", 
                             stringsAsFactors = FALSE)
  
  #file_content <- read.table(file.path(dir, file), header = F)[,-1]
  colnames(file_content) <- col_names

  # Extract all patterns like "maf_XXX_YYY.list"
matches <- unlist(regmatches(file, gregexpr("maf_[^\\.]+\\.list", file)))

# Remove "maf_" prefix and ".list" suffix
pops <- gsub("maf_|\\.list", "", matches)

  
  file_content$Populations <- paste(pops[1], pops[2], sep = "_")

  # Process the file content as needed
  fst_list[[file]] <- file_content
}

#Combine and filter for > 10 sites
fst_combined <- do.call(rbind, fst_list)
fst_combined_filter <- fst_combined[fst_combined$Nsites >= 10,]

#Check if all chromosomes are present
fst_stats <- fst_combined_filter %>%
                group_by(Populations) %>%
                summarise(n_chr = n_distinct(chr),
                          n_sites = sum(Nsites),
                          mean_Fst = round(mean(Fst),2 ),
                          sd_fst = sd(Fst)
)

printfst_stats)
```


## Step 3: Plot fst for Thingvallavatn
```{r}
#fst_stats$Pop2 <- fst_stats$Populations



# Create a named vector for the replacements
fst_stats$Lake <- case_when(startsWith(fst_stats$Populations, "Myv") ~ "Mývatn",
                                   startsWith(fst_stats$Populations,"Van")~ "Vangsvatnet",
                                   startsWith(fst_stats$Populations,"Thi")~ "Thingvallavatn",
                                   startsWith(fst_stats$Populations,"Sir")~ "Sirdalsvatnet",
                                   )

#Select Thingvalla only
fst_stats_thin <- fst_stats[fst_stats$Lake == "Thingvallavatn",]
fst_stats_thin$Populations
# Split the "Populations" column by "Thi" and remove any empty elements
splitted <- strsplit(fst_stats_thin$Populations, "_")
splitted <- lapply(splitted, function(x) x[x != ""])

# Add the split parts as new columns "Pop1" and "Pop2" to fst_stats_thin
fst_stats_thin$Pop1 <- sapply(splitted, function(x) x[1])
fst_stats_thin$Pop2 <- sapply(splitted, function(x) x[2])

fst_stats_thin$Pop1 <- gsub("Thi", "", fst_stats_thin$Pop1)
fst_stats_thin$Pop2 <- gsub("Thi", "", fst_stats_thin$Pop2)

fst_stats_thin <- fst_stats_thin[fst_stats_thin$Populations != "Thi_LB_SB_Thi_Pi_PL",]


# Add reverse combinations (symmetry) so that pop1 -> pop2 and pop2 -> pop1 are both represented

fst_data_dir <- data.frame(
  pop2 = fst_stats_thin$Pop1,
  pop1 = fst_stats_thin$Pop2,
  Fst = fst_stats_thin$mean_Fst
)

fst_data_rev <- data.frame(
  pop1 = fst_stats_thin$Pop1,
  pop2 = fst_stats_thin$Pop2,
  Fst = fst_stats_thin$mean_Fst
)

# Combine original and reverse data
fst_full <- rbind(fst_data_dir, fst_data_rev)

# Add diagonal values (Fst between the same population is 0)
unique_pops <- unique(c(fst_full$pop1, fst_full$pop2))
diag_data <- data.frame(
  pop1 = unique_pops,
  pop2 = unique_pops,
  Fst = 0
)

# Combine with diagonal data
fst_full <- rbind(fst_full, diag_data)

# Create a symmetric matrix
fst_matrix <- matrix(0, nrow = length(unique_pops), ncol = length(unique_pops),
                     dimnames = list(unique_pops, unique_pops))

# Fill the matrix with Fst values
for (i in 1:nrow(fst_full)) {
  fst_matrix[fst_full$pop1[i], fst_full$pop2[i]] <- fst_full$Fst[i]
}
row.names(fst_matrix)

#Order lakes 
desired_order <-  c("PL","Pi",     "LB", "SB")
fst_matrix_ordered <- fst_matrix[desired_order, desired_order, drop = FALSE]

#Prepare matrix to plot heatmap 
library(corrplot)
bright_colors <- colorRampPalette(c("blue", "orange"))(100)
pdf("~/Desktop/Comp_UU/REF_SalAlp_UK/PCA_NJ_tree/Fst_Thin_plot.pdf", width = 5, height = 6)
corrplot(fst_matrix_ordered, 
         method = 'number', 
         type = 'lower', 
         tl.col = "black",  
         tl.cex = 1.2, 
         col = bright_colors, 
         diag = F,
         tl.srt = 0)  # Set text labels to horizontal
dev.off()

```
